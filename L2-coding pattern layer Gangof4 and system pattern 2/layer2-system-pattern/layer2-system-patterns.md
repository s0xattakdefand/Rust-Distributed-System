Below is a concise Layer-2 System-Pattern Catalog—the “sibling” of your 24 GoF coding patterns.
Think of Layer 2 as the service-component level: everything that sits a notch above individual functions/modules but below full cross-domain platform design (Layers 3+).

| #  | System-level L2 pattern                 | One-sentence purpose                                         | Concrete use-case in 2025-style stacks                                                                                              |
| -- | --------------------------------------- | ------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------- |
| 1  | **API Gateway**                         | Single front-door that routes/filters all external traffic.  | A Rust-based Axum gateway multiplexes REST, GraphQL and gRPC into 30 micro-services; adds JWT auth + per-route rate-limits.         |
| 2  | **Backend-for-Frontend (BFF)**          | Tailor APIs for a specific UI or device.                     | A Next.js SPA hits a tiny Actix-web BFF that aggregates 7 internal services and returns view-ready JSON to cut browser round-trips. |
| 3  | **Service Registry / Discovery**        | Track healthy service instances and hand out endpoints.      | Consul + custom Rust sidecar registers each pod; clients pull healthy URLs via gRPC stream.                                         |
| 4  | **Sidecar / Ambassador**                | Attach cross-cutting helpers *per pod*.                      | Envoy proxy sidecar adds mTLS and request logging to an otherwise plain Tokio micro-service.                                        |
| 5  | **Circuit Breaker**                     | Fail fast after N errors to stop cascading outages.          | Tower-layer around every outbound HTTP client returns “ServiceUnavailable” after 50 % failure in 30 s.                              |
| 6  | **Retry with Back-off**                 | Auto-replay transient failures.                              | Reqwest client retries S3 uploads with exponential back-off + jitter, bounded to 3 attempts.                                        |
| 7  | **Bulkhead**                            | Isolate resource pools to stop noisy neighbours.             | Separate async-executor pools for “analytics” vs “checkout”; analytics crash won’t starve payment CPU quota.                        |
| 8  | **Rate Limiter / Throttler**            | Bound request rate per key.                                  | Redis-cell token-bucket keyed by API-key, enforced at gateway.                                                                      |
| 9  | **Token Propagation**                   | Forward end-user auth across service mesh.                   | Gateway issues short-lived HMAC-signed “transit” tokens; every hop validates before calling next service.                           |
| 10 | **Policy Gatekeeper**                   | Central policy decision + enforcement point.                 | OpenFGA server holds RBAC graph; Rust middleware queries it for every “/admin/\*” route.                                            |
| 11 | **Cache-Aside**                         | Let app fill caches as it goes.                              | Axum handler checks Redis for “product/123”; if miss, fetch from Postgres then `SETEX`.                                             |
| 12 | **Write-Through Cache**                 | All writes flow through cache first, keeping DB in sync.     | User-prefs stored in Aerospike; async job batches them to CockroachDB.                                                              |
| 13 | **CQRS Split**                          | Separate write (command) and read (query) models.            | Kafka topic collects orders (write), Materialize maintains real-time read-model for dashboards.                                     |
| 14 | **Event Sourcing**                      | Persist each state-changing event, rebuild state by replay.  | A Rust Axum ledger service appends `Credit`, `Debit` events to ScyllaDB; nightly job replays to derive balance.                     |
| 15 | **Saga / Process Manager**              | Coordinate long, distributed transactions with compensation. | Purchase flow: reserve inventory → capture payment → arrange shipping; failures roll back via compensators.                         |
| 16 | **Idempotent Receiver**                 | Accept duplicates safely.                                    | Upstash Kafka key dedupe + idempotency-key header ensures “charge card” runs once per order.                                        |
| 17 | **Message Broker (Queue)**              | Decouple producers/consumers, level traffic.                 | NATS JetStream sits between IoT devices and Rust async processors; handles 2 M msgs/s bursts.                                       |
| 18 | **Publish/Subscribe Bus**               | Broadcast events to N listeners.                             | Tokio-based WebSocket hub sends “price-update” to chart UI, alert service, and ML predictor simultaneously.                         |
| 19 | **Distributed Tracing**                 | Correlate logs across hops.                                  | OpenTelemetry spans emitted from every `tower::Service`; Jaeger UI shows flame-graph of checkout latency.                           |
| 20 | **Centralised Metrics / Observability** | Scrape, store, query operational data.                       | Prometheus pulls from `/metrics`; Grafana board shows p95 latency per route.                                                        |
| 21 | **Blue/Green Deploy**                   | Deploy new version alongside old, flip traffic.              | Argo Rollouts shifts 10 % traffic chunks to v2 of recommendation-engine pod.                                                        |
| 22 | **Canary + Automatic Rollback**         | Release small, watch SLO, auto-revert on error.              | Linkerd’s SMI metrics feed Rollout; >2 % 5xx reverts to previous build in 30 s.                                                     |
| 23 | **Infrastructure-as-Code**              | Immutable, version-controlled infra.                         | Terraform defines AWS VPC, RDS, S3; `cargo make deploy` triggers `terraform apply`.                                                 |
| 24 | **Self-Healing / Auto-Scaler**          | Detect failure or load and spin new units.                   | K8s HPA scales Rust gRPC worker from 3 to 30 pods on CPU>70 % and back to 3 at night.                                               |
